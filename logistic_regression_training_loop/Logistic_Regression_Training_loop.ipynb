{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d036d5-ac3e-4808-b5f6-9ff9938a66db",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\" />\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/>\n",
    "  <title>Logistic Regression (Slow Explanation)</title>\n",
    "  <style>\n",
    "    body{\n",
    "      font-family: Arial, Helvetica, sans-serif;\n",
    "      line-height: 1.6;\n",
    "      margin: 0;\n",
    "      background: #f5f7fb;\n",
    "      color: #222;\n",
    "    }\n",
    "    .container{\n",
    "      max-width: 900px;\n",
    "      margin: 30px auto;\n",
    "      padding: 20px;\n",
    "      background: white;\n",
    "      border-radius: 12px;\n",
    "      box-shadow: 0 4px 15px rgba(0,0,0,0.08);\n",
    "    }\n",
    "    h1{\n",
    "      text-align: center;\n",
    "      color: #0b3d91;\n",
    "    }\n",
    "    h2{\n",
    "      color: #0b3d91;\n",
    "      margin-top: 30px;\n",
    "    }\n",
    "    .box{\n",
    "      background: #eef4ff;\n",
    "      border-left: 6px solid #0b3d91;\n",
    "      padding: 12px 15px;\n",
    "      border-radius: 8px;\n",
    "      margin: 10px 0;\n",
    "    }\n",
    "    code{\n",
    "      background: #111;\n",
    "      color: #fff;\n",
    "      padding: 2px 6px;\n",
    "      border-radius: 5px;\n",
    "      font-size: 0.95em;\n",
    "    }\n",
    "    pre{\n",
    "      background: #111;\n",
    "      color: #fff;\n",
    "      padding: 15px;\n",
    "      border-radius: 10px;\n",
    "      overflow-x: auto;\n",
    "      font-size: 0.95em;\n",
    "    }\n",
    "    ul{\n",
    "      margin: 8px 0 8px 20px;\n",
    "    }\n",
    "    .math{\n",
    "      font-family: \"Courier New\", monospace;\n",
    "      background: #fafafa;\n",
    "      padding: 8px 10px;\n",
    "      border-radius: 8px;\n",
    "      border: 1px solid #ddd;\n",
    "      display: inline-block;\n",
    "      margin: 5px 0;\n",
    "    }\n",
    "    .recap{\n",
    "      background: #e7ffe7;\n",
    "      border-left: 6px solid #1f8f1f;\n",
    "      padding: 12px 15px;\n",
    "      border-radius: 8px;\n",
    "      margin-top: 25px;\n",
    "      font-weight: bold;\n",
    "    }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <div class=\"container\">\n",
    "    <h1>Logistic Regression (Slow Explanation)</h1>\n",
    "\n",
    "    <h2>1) What problem does Logistic Regression solve?</h2>\n",
    "    <p>\n",
    "      Logistic Regression is used for <b>classification</b>, mostly <b>binary classification</b>.\n",
    "    </p>\n",
    "\n",
    "    <div class=\"box\">\n",
    "      <b>Examples:</b>\n",
    "      <ul>\n",
    "        <li>Email: spam (1) or not spam (0)</li>\n",
    "        <li>Student: pass (1) or fail (0)</li>\n",
    "        <li>Message: scam (1) or real (0)</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "\n",
    "    <p>So your target/output is usually:</p>\n",
    "    <p class=\"math\">y ∈ {0, 1}</p>\n",
    "\n",
    "    <h2>2) The main idea (very important)</h2>\n",
    "    <p>\n",
    "      Logistic Regression tries to predict the <b>probability</b> that something belongs to class <b>1</b>.\n",
    "    </p>\n",
    "\n",
    "    <p>So it outputs:</p>\n",
    "    <p class=\"math\">ŷ = P(y = 1 | x)</p>\n",
    "\n",
    "    <div class=\"box\">\n",
    "      <b>Example:</b>\n",
    "      <ul>\n",
    "        <li>If model says 0.90 → 90% chance it is class 1</li>\n",
    "        <li>If model says 0.20 → 20% chance it is class 1</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "\n",
    "    <p>Then we convert probability into a class:</p>\n",
    "    <ul>\n",
    "      <li>If <span class=\"math\">ŷ ≥ 0.5</span> → predict <b>1</b></li>\n",
    "      <li>Else → predict <b>0</b></li>\n",
    "    </ul>\n",
    "\n",
    "    <h2>3) How does the model calculate that probability?</h2>\n",
    "    <p>First, it makes a <b>linear score</b> (like linear regression):</p>\n",
    "\n",
    "    <p class=\"math\">z = w₁x₁ + w₂x₂ + ... + wₙxₙ + b</p>\n",
    "\n",
    "    <p>Short form:</p>\n",
    "    <p class=\"math\">z = wᵀx + b</p>\n",
    "\n",
    "    <div class=\"box\">\n",
    "      <b>Where:</b>\n",
    "      <ul>\n",
    "        <li><span class=\"math\">x</span> = input features</li>\n",
    "        <li><span class=\"math\">w</span> = weights (importance of each feature)</li>\n",
    "        <li><span class=\"math\">b</span> = bias (shifts the decision)</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "\n",
    "    <p>\n",
    "      ⚠️ But <span class=\"math\">z</span> can be any number (negative, positive, large, small).\n",
    "      We need a probability between <b>0 and 1</b>.\n",
    "    </p>\n",
    "\n",
    "    <h2>4) The Sigmoid function (the “magic” part)</h2>\n",
    "    <p>We use the sigmoid function:</p>\n",
    "    <p class=\"math\">σ(z) = 1 / (1 + e<sup>-z</sup>)</p>\n",
    "\n",
    "    <p>So the prediction is:</p>\n",
    "    <p class=\"math\">ŷ = σ(z)</p>\n",
    "\n",
    "    <div class=\"box\">\n",
    "      <b>What sigmoid does:</b>\n",
    "      <ul>\n",
    "        <li>If <span class=\"math\">z</span> is big positive → sigmoid ≈ 1</li>\n",
    "        <li>If <span class=\"math\">z = 0</span> → sigmoid = 0.5</li>\n",
    "        <li>If <span class=\"math\">z</span> is big negative → sigmoid ≈ 0</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "\n",
    "    <p><b>Examples:</b></p>\n",
    "    <ul>\n",
    "      <li><span class=\"math\">z = 5</span> → <span class=\"math\">ŷ ≈ 0.99</span></li>\n",
    "      <li><span class=\"math\">z = 0</span> → <span class=\"math\">ŷ = 0.5</span></li>\n",
    "      <li><span class=\"math\">z = -5</span> → <span class=\"math\">ŷ ≈ 0.01</span></li>\n",
    "    </ul>\n",
    "\n",
    "    <p>\n",
    "      So sigmoid “squashes” any number into <b>[0, 1]</b>.\n",
    "    </p>\n",
    "\n",
    "    <h2>5) Why not just use Linear Regression for classification?</h2>\n",
    "    <p>\n",
    "      Because linear regression outputs values like:\n",
    "    </p>\n",
    "    <ul>\n",
    "      <li>-3.2</li>\n",
    "      <li>4.8</li>\n",
    "      <li>100</li>\n",
    "    </ul>\n",
    "\n",
    "    <p>\n",
    "      Those are <b>not probabilities</b>.\n",
    "      Logistic regression is built to output probabilities.\n",
    "    </p>\n",
    "\n",
    "    <h2>6) How does it learn? (Training)</h2>\n",
    "    <p>The model starts with random/zero weights:</p>\n",
    "    <p class=\"math\">w = 0, b = 0</p>\n",
    "\n",
    "    <p>Then it predicts:</p>\n",
    "    <p class=\"math\">ŷ = σ(Xw + b)</p>\n",
    "\n",
    "    <p>Then it compares prediction vs real answer:</p>\n",
    "    <p class=\"math\">error = ŷ - y</p>\n",
    "\n",
    "    <p>Then it updates weights to reduce error.</p>\n",
    "\n",
    "    <h2>7) The Loss function (how it measures “wrongness”)</h2>\n",
    "    <p>Logistic regression uses <b>Log Loss / Cross-Entropy Loss</b>.</p>\n",
    "\n",
    "    <p>For one example:</p>\n",
    "    <p class=\"math\">L = -[ y log(ŷ) + (1 - y) log(1 - ŷ) ]</p>\n",
    "\n",
    "    <div class=\"box\">\n",
    "      <b>Meaning:</b>\n",
    "      <ul>\n",
    "        <li>If the true label is 1 → it punishes the model if <span class=\"math\">ŷ</span> is low</li>\n",
    "        <li>If the true label is 0 → it punishes the model if <span class=\"math\">ŷ</span> is high</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "\n",
    "    <h2>8) Gradient Descent (how it improves)</h2>\n",
    "    <p>To reduce the loss, we use gradient descent:</p>\n",
    "\n",
    "    <p class=\"math\">w := w - α · (∂L/∂w)</p><br/>\n",
    "    <p class=\"math\">b := b - α · (∂L/∂b)</p>\n",
    "\n",
    "    <div class=\"box\">\n",
    "      <b>Where:</b>\n",
    "      <ul>\n",
    "        <li><span class=\"math\">α</span> = learning rate (step size)</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "\n",
    "    <h2>9) Logistic regression in code terms</h2>\n",
    "    <p>In code, logistic regression training looks like this:</p>\n",
    "\n",
    "    <pre>\n",
    "Step 1: compute score\n",
    "z = X @ w + b\n",
    "\n",
    "Step 2: convert to probability\n",
    "y_hat = sigmoid(z)\n",
    "\n",
    "Step 3: compute gradients\n",
    "error = y_hat - y\n",
    "dw = (X.T @ error) / n\n",
    "db = error.mean()\n",
    "\n",
    "Step 4: update parameters\n",
    "w -= lr * dw\n",
    "b -= lr * db\n",
    "    </pre>\n",
    "\n",
    "    <h2>10) Intuition: what are weights doing?</h2>\n",
    "    <p>\n",
    "      If a feature is strongly related to class 1, the model learns a <b>positive weight</b>:\n",
    "    </p>\n",
    "    <ul>\n",
    "      <li>bigger x → bigger z → sigmoid closer to 1</li>\n",
    "    </ul>\n",
    "\n",
    "    <p>\n",
    "      If a feature makes it more likely to be class 0, weight becomes <b>negative</b>:\n",
    "    </p>\n",
    "    <ul>\n",
    "      <li>bigger x → smaller z → sigmoid closer to 0</li>\n",
    "    </ul>\n",
    "\n",
    "    <h2>11) Decision boundary (simple meaning)</h2>\n",
    "    <p>\n",
    "      Logistic regression separates data using a line/plane.\n",
    "    </p>\n",
    "\n",
    "    <p>Decision rule:</p>\n",
    "    <p class=\"math\">ŷ = 1 if ŷ ≥ 0.5</p>\n",
    "\n",
    "    <p>\n",
    "      Since sigmoid is 0.5 at <span class=\"math\">z = 0</span>, the boundary is:\n",
    "    </p>\n",
    "\n",
    "    <p class=\"math\">z = wᵀx + b = 0</p>\n",
    "\n",
    "    <p>\n",
    "      That’s the “line” separating class 0 and class 1.\n",
    "    </p>\n",
    "\n",
    "    <div class=\"recap\">\n",
    "      ✅ Quick recap: Logistic regression = linear model + sigmoid + cross-entropy loss,\n",
    "      trained with gradient descent to output probabilities for classification.\n",
    "    </div>\n",
    "  </div>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97791ff6-5b71-44ba-b20b-6931624aceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _sigmoid(z):\n",
    "    \"\"\"Numerically stable sigmoid implementation.\"\"\"\n",
    "    return np.where(z >= 0, 1/(1+np.exp(-z)), np.exp(z)/(1+np.exp(z)))\n",
    "\n",
    "def train_logistic_regression(X, y, lr=0.1, steps=1000):\n",
    "    \"\"\"\n",
    "    Train logistic regression via gradient descent.\n",
    "    Return (w, b).\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y, dtype=float).reshape(-1)\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Initialize parameters\n",
    "    w = np.zeros(n_features, dtype=float)\n",
    "    b = 0.0\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # Linear model\n",
    "        z = X @ w + b\n",
    "\n",
    "        # Prediction (probabilities)\n",
    "        y_hat = _sigmoid(z)\n",
    "\n",
    "        # Gradients\n",
    "        error = y_hat - y\n",
    "        dw = (X.T @ error) / n_samples\n",
    "        db = np.sum(error) / n_samples\n",
    "\n",
    "        # Update\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dccd44-b1ec-4bb5-bdf7-a4a8b2a69c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
